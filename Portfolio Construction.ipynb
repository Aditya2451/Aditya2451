{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d6f5f323",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pypfopt import EfficientFrontier, risk_models, expected_returns, plotting\n",
    "import cvxpy as cp\n",
    "from pypfopt.exceptions import OptimizationError\n",
    "\n",
    "# Load data\n",
    "emissions_data = pd.read_csv(r\"C:\\Users\\adhit\\OneDrive\\desktop\\GDS\\Green Data Science project\\DATA\\Emissions Data_66 stocks.csv\")\n",
    "returns_data = pd.read_csv(r\"C:\\Users\\adhit\\OneDrive\\desktop\\GDS\\Green Data Science project\\DATA\\Market Price_66 stocks.csv\", index_col='Date', parse_dates=True, usecols=range(67))\n",
    "sector_data = pd.read_csv(r\"C:\\Users\\adhit\\OneDrive\\desktop\\GDS\\Green Data Science project\\DATA\\sector.csv\")\n",
    "\n",
    "# Data Cleansing\n",
    "emissions_data.columns = emissions_data.columns.str.strip()\n",
    "emissions_data = emissions_data.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n",
    "emissions_data['CO2 Equivalent Emissions Direct, Scope 1'] = emissions_data['CO2 Equivalent Emissions Direct, Scope 1'].str.replace(',', '').astype(float)\n",
    "emissions_data['CO2 Equivalent Emissions Indirect, Scope 2'] = emissions_data['CO2 Equivalent Emissions Indirect, Scope 2'].str.replace(',', '').astype(float)\n",
    "\n",
    "# Calculate total emissions for each instrument\n",
    "emissions_data['Total Emissions'] = emissions_data['CO2 Equivalent Emissions Direct, Scope 1'] + emissions_data['CO2 Equivalent Emissions Indirect, Scope 2']\n",
    "relevant_emissions = emissions_data.set_index('Instrument')['Total Emissions']\n",
    "\n",
    "# Ensure the tickers in returns_data match those in relevant_emissions\n",
    "tickers = returns_data.columns.intersection(relevant_emissions.index)\n",
    "\n",
    "# Filter returns_data and relevant_emissions to include only matching tickers\n",
    "returns_data_filtered = returns_data[tickers]\n",
    "relevant_emissions_filtered = relevant_emissions[tickers]\n",
    "\n",
    "# Calculate mean historical returns and sample covariance matrix\n",
    "mu = expected_returns.mean_historical_return(returns_data_filtered, frequency=12, returns_data=True)\n",
    "S = risk_models.risk_matrix(returns_data_filtered, method='ledoit_wolf', returns_data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b5359ddf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AA     0.165041\n",
      "AEO    0.072326\n",
      "AIZ    0.136892\n",
      "AKR   -0.053175\n",
      "AMP    0.283265\n",
      "         ...   \n",
      "WHR   -0.001174\n",
      "WOR    0.248323\n",
      "WSR    0.063667\n",
      "XHR   -0.048077\n",
      "XOM    0.163286\n",
      "Length: 66, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(mu) #Mean Historical returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "cb662c38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           AA       AEO       AIZ       AKR       AMP       APH       APO  \\\n",
      "AA   8.649444  2.608937  0.820894  3.586521  2.427404  2.102477  2.015700   \n",
      "AEO  2.608937  4.787959  0.622959  2.148176  1.448149  1.028997  1.524838   \n",
      "AIZ  0.820894  0.622959  1.303265  0.439531  0.371896  0.305162  0.335225   \n",
      "AKR  3.586521  2.148176  0.439531  3.522731  1.436860  1.083036  1.515414   \n",
      "AMP  2.427404  1.448149  0.371896  1.436860  2.191635  1.072006  1.500877   \n",
      "..        ...       ...       ...       ...       ...       ...       ...   \n",
      "WHR  2.501548  1.498721  0.597294  1.212828  1.315306  1.250646  1.221500   \n",
      "WOR  2.707792  1.910117  0.303637  1.494845  1.416197  1.144124  1.173015   \n",
      "WSR  3.304596  1.406121  0.538150  2.183253  1.263198  0.977856  1.055865   \n",
      "XHR  3.624285  2.086911  0.472853  2.951096  1.531916  1.099141  1.413029   \n",
      "XOM  2.083039  0.925740  0.114781  1.445982  1.089304  0.685072  1.222861   \n",
      "\n",
      "          AVB       AWR       AXP  ...       THS       TYL        UE  \\\n",
      "AA   1.727393  0.284270  2.293208  ...  0.739113  0.491665  3.442303   \n",
      "AEO  0.998357  0.255231  1.423282  ... -0.053019  0.375200  2.006962   \n",
      "AIZ  0.383476  0.117713  0.417395  ... -0.305865  0.068915  0.518897   \n",
      "AKR  1.280513  0.106469  1.697516  ...  0.268794  0.545068  2.521028   \n",
      "AMP  0.738456  0.242256  1.180871  ...  0.324033  0.504973  1.383465   \n",
      "..        ...       ...       ...  ...       ...       ...       ...   \n",
      "WHR  0.900081  0.174249  0.962698  ...  0.518559  0.391350  1.464119   \n",
      "WOR  0.632925  0.257961  1.245062  ...  0.563691  0.429491  1.440475   \n",
      "WSR  0.996964  0.099579  1.243532  ...  0.041707  0.275863  2.224069   \n",
      "XHR  1.167450  0.120749  1.977084  ...  0.552068  0.464524  2.423921   \n",
      "XOM  0.620234 -0.065708  1.082933  ...  0.745478  0.114914  1.437000   \n",
      "\n",
      "           VZ         W       WHR       WOR       WSR       XHR       XOM  \n",
      "AA   0.556499  4.208801  2.501548  2.707792  3.304596  3.624285  2.083039  \n",
      "AEO  0.257115  2.916364  1.498721  1.910117  1.406121  2.086911  0.925740  \n",
      "AIZ  0.208638  0.901665  0.597294  0.303637  0.538150  0.472853  0.114781  \n",
      "AKR  0.279647  1.802662  1.212828  1.494845  2.183253  2.951096  1.445982  \n",
      "AMP  0.274555  2.830422  1.315306  1.416197  1.263198  1.531916  1.089304  \n",
      "..        ...       ...       ...       ...       ...       ...       ...  \n",
      "WHR  0.393130  4.228401  3.148705  1.412772  1.089780  0.956295  0.888802  \n",
      "WOR  0.321035  2.589709  1.412772  3.462930  1.284464  1.664860  0.823245  \n",
      "WSR  0.370438  1.743986  1.089780  1.284464  2.991003  2.133989  1.164908  \n",
      "XHR  0.266628  1.535981  0.956295  1.664860  2.133989  4.628332  1.696340  \n",
      "XOM  0.263087  1.870112  0.888802  0.823245  1.164908  1.696340  2.569059  \n",
      "\n",
      "[66 rows x 66 columns]\n"
     ]
    }
   ],
   "source": [
    "print(S) #Sample Covariance Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1e63d452",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optimize for maximum Sharpe Ratio\n",
    "ef = EfficientFrontier(mu, S, weight_bounds=(0, 1))\n",
    "weights = ef.max_sharpe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0e28662c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert weights to a DataFrame\n",
    "tangency_weights = pd.DataFrame.from_dict(weights, orient='index', columns=['Weight'])\n",
    "\n",
    "# Ensure the index is named 'Tickers'\n",
    "tangency_weights.index.name = 'Tickers'\n",
    "\n",
    "# Filter and sort the weights\n",
    "filtered_weights = tangency_weights[tangency_weights['Weight'] > 0].sort_values(by='Weight', ascending=False)\n",
    "\n",
    "# Reset the index to convert the index into a column\n",
    "filtered_weights = filtered_weights.reset_index()\n",
    "\n",
    "# Rename the columns\n",
    "filtered_weights.columns = ['Tickers', 'Weight']\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "filtered_weights.to_csv('tangency_weights.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a98dc573",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date\n",
      "2019-06-01    0.085919\n",
      "2019-07-01   -0.024340\n",
      "2019-08-01    0.044941\n",
      "2019-09-01   -0.006753\n",
      "2019-10-01    0.033331\n",
      "2019-11-01    0.024436\n",
      "2019-12-01   -0.008887\n",
      "2020-01-01    0.009473\n",
      "2020-02-01   -0.063588\n",
      "2020-03-01   -0.055932\n",
      "2020-04-01    0.080577\n",
      "2020-05-01    0.147482\n",
      "2020-06-01    0.036470\n",
      "2020-07-01    0.024030\n",
      "2020-08-01    0.082817\n",
      "2020-09-01   -0.032907\n",
      "2020-10-01   -0.011245\n",
      "2020-11-01    0.155068\n",
      "2020-12-01    0.019044\n",
      "2021-01-01    0.009201\n",
      "2021-02-01    0.021131\n",
      "2021-03-01    0.066145\n",
      "2021-04-01    0.020547\n",
      "2021-05-01    0.028610\n",
      "2021-06-01    0.036616\n",
      "2021-07-01    0.019762\n",
      "2021-08-01    0.036571\n",
      "2021-09-01   -0.023959\n",
      "2021-10-01    0.064320\n",
      "2021-11-01    0.002713\n",
      "2021-12-01    0.029966\n",
      "2022-01-01   -0.058578\n",
      "2022-02-01    0.038413\n",
      "2022-03-01    0.036750\n",
      "2022-04-01   -0.078124\n",
      "2022-05-01    0.011008\n",
      "2022-06-01   -0.015492\n",
      "2022-07-01    0.100709\n",
      "2022-08-01    0.016655\n",
      "2022-09-01   -0.075477\n",
      "2022-10-01    0.108479\n",
      "2022-11-01    0.024443\n",
      "2022-12-01   -0.056180\n",
      "2023-01-01    0.061519\n",
      "2023-02-01   -0.004066\n",
      "2023-03-01    0.027421\n",
      "2023-04-01    0.019137\n",
      "2023-05-01   -0.031650\n",
      "2023-06-01    0.072831\n",
      "2023-07-01    0.049131\n",
      "2023-08-01    0.006278\n",
      "2023-09-01   -0.001621\n",
      "2023-10-01   -0.012979\n",
      "2023-11-01    0.073839\n",
      "2023-12-01    0.031145\n",
      "2024-01-01    0.025693\n",
      "2024-02-01    0.103283\n",
      "2024-03-01    0.025272\n",
      "2024-04-01   -0.004178\n",
      "2024-05-01    0.100259\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#Calculate tangency portfolio returns\n",
    "tangency_returns = (tangency_weights.T.values*returns_data).sum(axis=1)\n",
    "print(tangency_returns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "36712507",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Weight\n",
      "Tickers          \n",
      "AA       0.000000\n",
      "AEO      0.000000\n",
      "AIZ      0.041829\n",
      "AKR      0.000000\n",
      "AMP      0.000000\n",
      "...           ...\n",
      "WHR      0.000000\n",
      "WOR      0.000000\n",
      "WSR      0.000000\n",
      "XHR      0.000000\n",
      "XOM      0.000000\n",
      "\n",
      "[66 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "print(tangency_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c4ac6da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating performance metrics \n",
    "\n",
    "mu_tangency_monthly = tangency_returns.mean()\n",
    "mu_tangency_annual = (1+mu_tangency_monthly)**12-1\n",
    "\n",
    "sigma_sq_tangency = tangency_returns.var(ddof=1)\n",
    "sigma_tangency_monthly = tangency_returns.std(ddof=1)\n",
    "sigma_tangency_annual = sigma_tangency_monthly*np.sqrt(12)\n",
    "\n",
    "sr_tangency = mu_tangency_monthly/sigma_tangency_monthly*np.sqrt(12)\n",
    "\n",
    "num_inv_tangency = np.sum(tangency_weights.values>0)\n",
    "num_sectors_tangency = sector_data.merge(tangency_weights.loc[tangency_weights['Weight']>0], \n",
    "                                        left_on='Instrument', right_index=True)['TRBC Economic Sector Name'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "47b8d272",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mu_tangency_annual: 0.33065086313143044\n",
      "sigma_tangency_annual: 0.17372802365015497\n",
      "sr_tangency: 1.6640700425700523\n",
      "num_inv_tangency: 11\n",
      "num_sectors_tangency: 6\n"
     ]
    }
   ],
   "source": [
    "print(f\"mu_tangency_annual: {mu_tangency_annual}\")\n",
    "print(f\"sigma_tangency_annual: {sigma_tangency_annual}\")\n",
    "print(f\"sr_tangency: {sr_tangency}\")\n",
    "print(f\"num_inv_tangency: {num_inv_tangency}\")\n",
    "print(f\"num_sectors_tangency: {num_sectors_tangency}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "36ffb335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tangency Sector Weights:\n",
      " TRBC Economic Sector Name\n",
      "Basic Materials           0.000000\n",
      "Consumer Cyclicals        0.282539\n",
      "Consumer Non-Cyclicals    0.117865\n",
      "Energy                    0.024224\n",
      "Financials                0.095747\n",
      "Healthcare                0.000000\n",
      "Industrials               0.139074\n",
      "Real Estate               0.000000\n",
      "Technology                0.340552\n",
      "Utilities                 0.000000\n",
      "Name: Weight, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "tangency_sector_weights = tangency_weights.merge(sector_data, left_index=True, right_on='Instrument').groupby('TRBC Economic Sector Name')['Weight'].sum()\n",
    "print(\"Tangency Sector Weights:\\n\", tangency_sector_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86308396",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f34d3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Raw Emissions Tangency based Portfolio "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8e3dba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "bb6590a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the data\n",
    "emissions_data = pd.read_csv(r\"C:\\Users\\adhit\\OneDrive\\desktop\\GDS\\Green Data Science project\\DATA\\Emissions Data_66 stocks.csv\")\n",
    "returns_data = pd.read_csv(r\"C:\\Users\\adhit\\OneDrive\\desktop\\GDS\\Green Data Science project\\DATA\\Market Price_66 stocks.csv\", index_col='Date', parse_dates=True, usecols=range(67))\n",
    "weights_data = pd.read_csv(r\"C:\\Users\\adhit\\OneDrive\\desktop\\GDS\\Green Data Science project\\DATA\\tgncy_weights.csv\")  # Load the weights from the generated CSV\n",
    "\n",
    "# Strip leading and trailing spaces from the column names of emissions_data\n",
    "emissions_data.columns = emissions_data.columns.str.strip()\n",
    "\n",
    "# Strip leading and trailing spaces from the 'Instrument' column values\n",
    "emissions_data['Instrument'] = emissions_data['Instrument'].str.strip()\n",
    "\n",
    "# Set the index for easy access to rows based on Instrument\n",
    "emissions_data.set_index('Instrument', inplace=True)\n",
    "\n",
    "# Ensure the correct column names in weights_data\n",
    "weights_data.columns = ['Tickers', 'Weight']\n",
    "\n",
    "# Convert weights to a Series for easy manipulation\n",
    "weights = pd.Series(weights_data.set_index('Tickers')['Weight'])\n",
    "\n",
    "# Ensure matching data types for the indices\n",
    "returns_data.columns = returns_data.columns.astype(str)\n",
    "emissions_data.index = emissions_data.index.astype(str)\n",
    "weights.index = weights.index.astype(str)\n",
    "\n",
    "# Filter emissions data to match the tickers in returns_data\n",
    "direct_emissions = emissions_data.loc[returns_data.columns, 'CO2 Equivalent Emissions Direct, Scope 1']\n",
    "indirect_emissions = emissions_data.loc[returns_data.columns, 'CO2 Equivalent Emissions Indirect, Scope 2']\n",
    "\n",
    "# Remove commas and convert emissions data to float to ensure correct data types\n",
    "direct_emissions = direct_emissions.str.replace(',', '').astype(float)\n",
    "indirect_emissions = indirect_emissions.str.replace(',', '').astype(float)\n",
    "\n",
    "# Calculate the total emissions for each ticker\n",
    "total_emissions = direct_emissions + indirect_emissions\n",
    "\n",
    "# Ensure weights are float\n",
    "weights = weights.astype(float)\n",
    "\n",
    "# Calculate the weighted emissions for the portfolio\n",
    "# Reindex weights to match total_emissions index\n",
    "weights_reindexed = weights.reindex(total_emissions.index).fillna(0)\n",
    "\n",
    "# Ensure weights_reindexed and total_emissions are float\n",
    "weights_reindexed = weights_reindexed.astype(float)\n",
    "total_emissions = total_emissions.astype(float)\n",
    "\n",
    "# Perform the multiplication\n",
    "weighted_emissions = weights_reindexed * total_emissions\n",
    "\n",
    "# Calculate the sum of weighted emissions to get the 'Raw Emission of Market Cap Based Portfolio'\n",
    "raw_emission_tangency_based_portfolio = weighted_emissions.sum()\n",
    "\n",
    "# Create a DataFrame to store the results and save to CSV\n",
    "emission_results = pd.DataFrame({\n",
    "    'Ticker': total_emissions.index,\n",
    "    'Weight': weights_reindexed,\n",
    "    'Direct Emissions': direct_emissions,\n",
    "    'Indirect Emissions': indirect_emissions,\n",
    "    'Total Emissions': total_emissions,\n",
    "    'Weighted Emissions': weighted_emissions\n",
    "})\n",
    "\n",
    "emission_results.to_csv('raw_emission_tangency_based_portfolio.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "1cbcf1ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 15 Weights:\n",
      " BJ     0.282539\n",
      "BAH    0.167469\n",
      "HWM    0.139074\n",
      "NOW    0.088939\n",
      "GE     0.071816\n",
      "TYL    0.064191\n",
      "APO    0.053919\n",
      "HRB    0.046049\n",
      "AIZ    0.041829\n",
      "HES    0.024224\n",
      "APH    0.019953\n",
      "AA          NaN\n",
      "AEO         NaN\n",
      "AKR         NaN\n",
      "AMP         NaN\n",
      "dtype: float64\n",
      "Monthly Mean Return: 0.0241\n",
      "Annual Mean Return: 0.3307\n",
      "Monthly Volatility: 0.0502\n",
      "Annual Volatility: 0.1737\n",
      "Sharpe Ratio: 1.6641\n",
      "Number of Investments: 11\n",
      "Number of Sectors: 6\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'weights' contains the tangency portfolio weights\n",
    "# Ensure weights are correctly aligned with returns_data columns\n",
    "tangency_weights = pd.Series(weights, index=returns_data.columns).reindex(returns_data.columns, fill_value=0).values\n",
    "\n",
    "# Calculate the tangency portfolio returns\n",
    "tangency_returns = (returns_data * tangency_weights).sum(axis=1)\n",
    "\n",
    "# Calculate the monthly and annual mean returns for the tangency portfolio\n",
    "mu_tangency_monthly = tangency_returns.mean()\n",
    "mu_tangency_annual = (1 + mu_tangency_monthly) ** 12 - 1\n",
    "\n",
    "# Calculate the monthly and annual volatility (standard deviation) for the tangency portfolio\n",
    "sigma_tangency_monthly = tangency_returns.std(ddof=1)\n",
    "sigma_tangency_annual = sigma_tangency_monthly * np.sqrt(12)\n",
    "\n",
    "# Calculate the Sharpe Ratio for the tangency portfolio (assuming risk-free rate is 0)\n",
    "sr_tangency = mu_tangency_monthly / sigma_tangency_monthly * np.sqrt(12)\n",
    "\n",
    "# Count the number of investments and sectors in the tangency portfolio\n",
    "num_inv_tangency = np.sum(tangency_weights > 0)\n",
    "num_sectors_tangency = len(np.unique(sector_data.loc[sector_data['Instrument'].isin(returns_data.columns[tangency_weights > 0]), 'TRBC Economic Sector Name']))\n",
    "\n",
    "# Print the top 15 weights for the tangency portfolio\n",
    "top15_weights = pd.Series(tangency_weights, index=returns_data.columns).sort_values(ascending=False).head(15)\n",
    "print(\"Top 15 Weights:\\n\", top15_weights)\n",
    "print(f\"Monthly Mean Return: {mu_tangency_monthly:.4f}\")\n",
    "print(f\"Annual Mean Return: {mu_tangency_annual:.4f}\")\n",
    "print(f\"Monthly Volatility: {sigma_tangency_monthly:.4f}\")\n",
    "print(f\"Annual Volatility: {sigma_tangency_annual:.4f}\")\n",
    "print(f\"Sharpe Ratio: {sr_tangency:.4f}\")\n",
    "print(f\"Number of Investments: {num_inv_tangency}\")\n",
    "print(f\"Number of Sectors: {num_sectors_tangency}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "d9808092",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 15 Weights:\n",
      " [0.01515152 0.01515152 0.01515152 0.01515152 0.01515152 0.01515152\n",
      " 0.01515152 0.01515152 0.01515152 0.01515152 0.01515152 0.01515152\n",
      " 0.01515152 0.01515152 0.01515152 0.01515152 0.01515152 0.01515152\n",
      " 0.01515152 0.01515152 0.01515152 0.01515152 0.01515152 0.01515152\n",
      " 0.01515152 0.01515152 0.01515152 0.01515152 0.01515152 0.01515152\n",
      " 0.01515152 0.01515152 0.01515152 0.01515152 0.01515152 0.01515152\n",
      " 0.01515152 0.01515152 0.01515152 0.01515152 0.01515152 0.01515152\n",
      " 0.01515152 0.01515152 0.01515152 0.01515152 0.01515152 0.01515152\n",
      " 0.01515152 0.01515152 0.01515152 0.01515152 0.01515152 0.01515152\n",
      " 0.01515152 0.01515152 0.01515152 0.01515152 0.01515152 0.01515152\n",
      " 0.01515152 0.01515152 0.01515152 0.01515152 0.01515152 0.01515152]\n",
      "Monthly Mean Return: 0.014277600506310523\n",
      "Annual Mean Return: 0.1854466524986762\n",
      "Monthly Volatility: 0.06908643322599198\n",
      "Annual Volatility: 0.23932242492226544\n",
      "Sharpe Ratio: 0.7159011786353766\n",
      "Number of Investments: 66\n",
      "Number of Sectors: 66\n"
     ]
    }
   ],
   "source": [
    "# Calculate the benchmark returns (e.g., an equally weighted portfolio or a specific benchmark)\n",
    "benchmark_weights = np.ones(len(returns_data.columns)) / len(returns_data.columns)\n",
    "benchmark_returns = (returns_data * benchmark_weights).sum(axis=1)\n",
    "\n",
    "# Calculate the monthly and annual mean returns for the benchmark\n",
    "mu_benchmark_monthly = benchmark_returns.mean()\n",
    "mu_benchmark_annual = (1 + mu_benchmark_monthly) ** 12 - 1\n",
    "\n",
    "# Calculate the monthly and annual volatility (standard deviation) for the benchmark\n",
    "sigma_benchmark_monthly = benchmark_returns.std(ddof=1)\n",
    "sigma_benchmark_annual = sigma_benchmark_monthly * np.sqrt(12)\n",
    "\n",
    "# Calculate the Sharpe Ratio for the benchmark (assuming risk-free rate is 0)\n",
    "sr_benchmark = mu_benchmark_monthly / sigma_benchmark_monthly * np.sqrt(12)\n",
    "                                                                        \n",
    "# Define the benchmark emissions (e.g., an equally weighted portfolio or a specific benchmark)\n",
    "benchmark_emissions = (total_emissions * benchmark_weights).sum()\n",
    "\n",
    "# Count the number of investments and sectors in the benchmark\n",
    "num_inv_benchmark = np.sum(benchmark_weights > 0)\n",
    "num_sectors_benchmark = returns_data.columns.nunique()\n",
    "\n",
    "# Print the top 15 weights (though for an equally weighted portfolio, all weights are the same)                                                                  \n",
    "print(\"Top 15 Weights:\\n\", benchmark_weights)\n",
    "print(f\"Monthly Mean Return: {mu_benchmark_monthly}\")\n",
    "print(f\"Annual Mean Return: {mu_benchmark_annual}\")\n",
    "print(f\"Monthly Volatility: {sigma_benchmark_monthly}\")\n",
    "print(f\"Annual Volatility: {sigma_benchmark_annual}\")\n",
    "print(f\"Sharpe Ratio: {sr_benchmark}\")\n",
    "print(f\"Number of Investments: {num_inv_benchmark}\")\n",
    "print(f\"Number of Sectors: {num_sectors_benchmark}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a3c8f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce470e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Constrained Portfolio - 10% Reduced Emissions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e51be4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "b2f95982",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 15 Weights:\n",
      "        Weight\n",
      "AA   0.008504\n",
      "AEO  0.014865\n",
      "AIZ  0.014821\n",
      "AKR  0.031128\n",
      "AMP  0.029059\n",
      "..        ...\n",
      "WHR  0.009298\n",
      "WOR  0.017149\n",
      "WSR  0.013674\n",
      "XHR  0.016906\n",
      "XOM  0.004262\n",
      "\n",
      "[66 rows x 1 columns]\n",
      "Monthly Mean Return: 0.013868277790965658\n",
      "Annual Mean Return: 0.17971857946975112\n",
      "Monthly Volatility: 0.06908642695839595\n",
      "Annual Volatility: 0.2393224032106759\n",
      "Sharpe Ratio: 0.6953771617657067\n",
      "Tracking Error: 1.7521689412677686e-07\n",
      "Number of Investments: 66\n",
      "Number of Sectors: 3\n",
      "Total Emissions: 3306780.232384445\n",
      "Sector Weights:\n",
      " TRBC Economic Sector Name\n",
      "Sector A    0.363301\n",
      "Sector B    0.292814\n",
      "Sector C    0.343885\n",
      "Name: Weight, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Ensure Carbon Intensity values are strings, remove commas, and convert to float\n",
    "emissions_data['Carbon Intensity'] = emissions_data['Carbon Intensity'].astype(str).str.replace(',', '').astype(float)\n",
    "\n",
    "# Define constraints\n",
    "def TE(w, portfolio_returns, benchmark_returns):\n",
    "    xi = (w @ portfolio_returns.T - benchmark_returns.values.reshape(-1))\n",
    "    mean = cp.sum(xi) / len(benchmark_returns)\n",
    "    return cp.sum_squares(xi - mean)\n",
    "\n",
    "def CI(w, portfolio_intensity):\n",
    "    xi = w @ portfolio_intensity.T\n",
    "    carbon_intensity = cp.sum(xi)\n",
    "    return carbon_intensity\n",
    "\n",
    "ef_constrained1 = EfficientFrontier(mu, S, weight_bounds=(0, 1))\n",
    "\n",
    "ef_constrained1.add_constraint(lambda w: TE(w, returns_data, benchmark_returns) <= 0.1**2)\n",
    "ef_constrained1.add_constraint(lambda w: CI(w, emissions_data['Carbon Intensity']) <= 0.9 * benchmark_emissions)\n",
    "weights = ef_constrained1.convex_objective(TE, portfolio_returns=returns_data, benchmark_returns=benchmark_returns)\n",
    "\n",
    "#Calculate the total emissionsfor the constrained portfolio\n",
    "constrained1_weights = pd.DataFrame.from_dict(weights, orient='index', columns=['Weight'])\n",
    "constrained1_weights[constrained1_weights['Weight']>0].sort_values(by='Weight', ascending=False)\n",
    "\n",
    "constrained1_returns = (constrained1_weights.T.values*returns_data).sum(axis=1)\n",
    "\n",
    "mu_constrained1_monthly = constrained1_returns.mean()\n",
    "mu_constrained1_annual = (1+mu_constrained1_monthly)**12-1\n",
    "\n",
    "sigma_sq_constrained1 = constrained1_returns.var(ddof=1)\n",
    "sigma_constrained1_monthly = constrained1_returns.std(ddof=1)\n",
    "sigma_constrained1_annual = sigma_constrained1_monthly*np.sqrt(12)\n",
    "\n",
    "sr_constrained1 = mu_constrained1_monthly/sigma_constrained1_monthly*np.sqrt(12)\n",
    "\n",
    "constrained1_te = (constrained1_returns - benchmark_returns.T).values.std(ddof=1)\n",
    "\n",
    "num_inv_constrained1 = np.sum(constrained1_weights.values>10**-4)\n",
    "num_sectors_constrained1 = df_sector.merge(constrained1_weights.loc[constrained1_weights['Weight']>10**-4], \n",
    "                                        left_on='Instrument', right_index=True)['TRBC Economic Sector Name'].nunique()\n",
    "\n",
    "#Calculate the emissions for the constrained portfolio\n",
    "constrained1_emissions = (constrained1_weights['Weight'].values * total_emissions.values).sum()\n",
    "\n",
    "c1_sector_weights = constrained1_weights.merge(df_sector, left_index=True, right_on='Instrument').groupby('TRBC Economic Sector Name')['Weight'].sum()\n",
    "\n",
    "print(\"Top 15 Weights:\\n\", constrained1_weights)\n",
    "print(f\"Monthly Mean Return: {mu_constrained1_monthly}\")\n",
    "print(f\"Annual Mean Return: {mu_constrained1_annual}\")\n",
    "print(f\"Monthly Volatility: {sigma_constrained1_monthly}\")\n",
    "print(f\"Annual Volatility: {sigma_constrained1_annual}\")\n",
    "print(f\"Sharpe Ratio: {sr_constrained1}\")\n",
    "print(f\"Tracking Error: {constrained1_te}\")\n",
    "print(f\"Number of Investments: {num_inv_constrained1}\")\n",
    "print(f\"Number of Sectors: {num_sectors_constrained1}\")\n",
    "print(f\"Total Emissions: {constrained1_emissions}\")\n",
    "print(\"Sector Weights:\\n\", c1_sector_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "f572e413",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "483e3ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Constrained Portfolio - 20% Carbon Intensity Reduction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "68bc8606",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "d7b2747f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 15 Weights:\n",
      "        Weight\n",
      "AA   0.006374\n",
      "AEO  0.013503\n",
      "AIZ  0.016544\n",
      "AKR  0.036580\n",
      "AMP  0.036016\n",
      "..        ...\n",
      "WHR  0.006722\n",
      "WOR  0.019456\n",
      "WSR  0.011017\n",
      "XHR  0.018446\n",
      "XOM  0.001206\n",
      "\n",
      "[66 rows x 1 columns]\n",
      "Monthly Mean Return: 0.013693019957461776\n",
      "Annual Mean Return: 0.17727378298420704\n",
      "Monthly Volatility: 0.0690864327542376\n",
      "Annual Volatility: 0.23932242328806036\n",
      "Sharpe Ratio: 0.686589401995826\n",
      "Tracking Error: 1.9377843059993325e-08\n",
      "Number of Investments: 66\n",
      "Number of Sectors: 3\n",
      "Total Emissions: 2901376.7532237875\n",
      "Sector Weights:\n",
      " TRBC Economic Sector Name\n",
      "Basic Materials           0.056291\n",
      "Consumer Cyclicals        0.174689\n",
      "Consumer Non-Cyclicals    0.115367\n",
      "Energy                    0.051382\n",
      "Financials                0.145208\n",
      "Healthcare                0.031039\n",
      "Industrials               0.091394\n",
      "Real Estate               0.141192\n",
      "Technology                0.071138\n",
      "Utilities                 0.122299\n",
      "Name: Weight, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "ef_constrained2 = EfficientFrontier(mu, S, weight_bounds=(0, 1))\n",
    "\n",
    "ef_constrained2.add_constraint(lambda w: TE(w, returns_data, benchmark_returns) <= 0.1**2)\n",
    "ef_constrained2.add_constraint(lambda w: CI(w, emissions_data['Carbon Intensity']) <= 0.8*benchmark_emissions)\n",
    "weights = ef_constrained2.convex_objective(TE, portfolio_returns= returns_data, benchmark_returns=benchmark_returns)\n",
    "constrained2_weights = pd.DataFrame.from_dict(weights, orient='index', columns=['Weight'])\n",
    "constrained2_weights[constrained2_weights['Weight']>10**-6].sort_values(by='Weight', ascending=False)\n",
    "\n",
    "constrained2_returns = (constrained2_weights.T.values*returns_data).sum(axis=1)\n",
    "\n",
    "mu_constrained2_monthly = constrained2_returns.mean()\n",
    "mu_constrained2_annual = (1+mu_constrained2_monthly)**12-1\n",
    "\n",
    "sigma_sq_constrained2 =constrained2_returns.var(ddof=1)\n",
    "sigma_constrained2_monthly = constrained2_returns.std(ddof=1)\n",
    "sigma_constrained2_annual = sigma_constrained2_monthly*np.sqrt(12)\n",
    "\n",
    "sr_constrained2 = mu_constrained2_monthly/sigma_constrained2_monthly*np.sqrt(12)\n",
    "\n",
    "constrained2_te = (constrained2_returns - benchmark_returns.T).values.std(ddof=1)\n",
    "\n",
    "num_inv_constrained2 = np.sum(constrained2_weights.values>10**-6)\n",
    "num_sectors_constrained2 = df_sector.merge(constrained2_weights.loc[constrained2_weights['Weight']>10**-6], \n",
    "                                        left_on='Instrument', right_index=True)['TRBC Economic Sector Name'].nunique()\n",
    "constrained2_emissions = (constrained2_weights['Weight'].values * total_emissions.values).sum()\n",
    "\n",
    "c2_sector_weights = constrained2_weights.merge(sector_data, left_index=True, right_on='Instrument').groupby('TRBC Economic Sector Name')['Weight'].sum()\n",
    "\n",
    "print(\"Top 15 Weights:\\n\", constrained2_weights)\n",
    "print(f\"Monthly Mean Return: {mu_constrained2_monthly}\")\n",
    "print(f\"Annual Mean Return: {mu_constrained2_annual}\")\n",
    "print(f\"Monthly Volatility: {sigma_constrained2_monthly}\")\n",
    "print(f\"Annual Volatility: {sigma_constrained2_annual}\")\n",
    "print(f\"Sharpe Ratio: {sr_constrained2}\")\n",
    "print(f\"Tracking Error: {constrained2_te}\")\n",
    "print(f\"Number of Investments: {num_inv_constrained2}\")\n",
    "print(f\"Number of Sectors: {num_sectors_constrained2}\")\n",
    "print(f\"Total Emissions: {constrained2_emissions}\")\n",
    "print(\"Sector Weights:\\n\", c2_sector_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "27f7485a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "fb979160",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Constrained Portfolio - 50% Reduction in Carbon Intensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "6ed8ba50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "01188a68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 15 Weights:\n",
      "            Weight\n",
      "AA   2.241386e-03\n",
      "AEO  6.270508e-03\n",
      "AIZ  2.009310e-02\n",
      "AKR  4.279344e-02\n",
      "AMP  4.735579e-02\n",
      "..            ...\n",
      "WHR  5.550544e-03\n",
      "WOR  2.037656e-02\n",
      "WSR  1.333657e-02\n",
      "XHR  1.640618e-02\n",
      "XOM  6.743303e-07\n",
      "\n",
      "[66 rows x 1 columns]\n",
      "Monthly Mean Return: 0.013673610616173759\n",
      "Annual Mean Return: 0.17700331409056735\n",
      "Monthly Volatility: 0.06908479475522827\n",
      "Annual Volatility: 0.23931674909304654\n",
      "Sharpe Ratio: 0.6856324432615846\n",
      "Tracking Error: 0.00018642680628404594\n",
      "Number of Investments: 58\n",
      "Number of Sectors: 10\n",
      "Total Emissions: 26692875363.1095\n",
      "Sector Weights:\n",
      " TRBC Economic Sector Name\n",
      "Sector A    0.330820\n",
      "Sector B    0.282942\n",
      "Sector C    0.386238\n",
      "Name: Weight, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "ef_constrained3 = EfficientFrontier(mu, S, weight_bounds=(0, 1))\n",
    "\n",
    "ef_constrained3.add_constraint(lambda w: TE(w, returns_data, benchmark_returns) <= 0.1**2)\n",
    "ef_constrained3.add_constraint(lambda w: CI(w, emissions_data['Carbon Intensity']) <= 0.5*benchmark_emissions)\n",
    "weights = ef_constrained3.convex_objective(TE, portfolio_returns=returns_data, benchmark_returns=benchmark_returns)\n",
    "\n",
    "constrained3_weights = pd.DataFrame.from_dict(weights, orient='index', columns=['Weight'])\n",
    "constrained3_weights[constrained3_weights['Weight']>10**-4].sort_values(by='Weight', ascending=False).head(15)\n",
    "# Ensure all relevant columns are numeric\n",
    "emissions_data = emissions_data.apply(lambda x: x.str.replace(',', '').astype(float) if x.dtype == 'object' else x)\n",
    "\n",
    "# Calculate the returns for the constrained portfolio\n",
    "constrained3_returns = (constrained3_weights['Weight'].values * returns_data).sum(axis=1)\n",
    "\n",
    "# Calculate the monthly and annual mean returns\n",
    "mu_constrained3_monthly = constrained3_returns.mean()\n",
    "mu_constrained3_annual = (1 + mu_constrained3_monthly) ** 12 - 1\n",
    "\n",
    "# Calculate the monthly and annual standard deviation (volatility)\n",
    "sigma_sq_constrained3 = constrained3_returns.var(ddof=1)\n",
    "sigma_constrained3_monthly = constrained3_returns.std(ddof=1)\n",
    "sigma_constrained3_annual = sigma_constrained3_monthly * np.sqrt(12)\n",
    "\n",
    "# Calculate the Sharpe Ratio\n",
    "sr_constrained3 = mu_constrained3_monthly / sigma_constrained3_monthly * np.sqrt(12)\n",
    "\n",
    "# Calculate the tracking error\n",
    "constrained3_te = (constrained3_returns - benchmark_returns.values).std(ddof=1)\n",
    "\n",
    "# Count the number of investments and sectors in the constrained portfolio\n",
    "num_inv_constrained3 = np.sum(constrained3_weights['Weight'].values > 10**-4)\n",
    "num_sectors_constrained3 = sector_data.merge(constrained3_weights[constrained3_weights['Weight'] > 10**-4], \n",
    "                                           left_on='Instrument', right_index=True)['TRBC Economic Sector Name'].nunique()\n",
    "\n",
    "# Calculate the total emissions for the constrained portfolio\n",
    "constrained3_emissions = (constrained3_weights['Weight'].values * emissions_data.sum(axis=1).values).sum()\n",
    "\n",
    "c3_sector_weights = constrained3_weights.merge(df_sector, left_index=True, right_on='Instrument').groupby('TRBC Economic Sector Name')['Weight'].sum()\n",
    "\n",
    "print(\"Top 15 Weights:\\n\", constrained3_weights)\n",
    "print(f\"Monthly Mean Return: {mu_constrained3_monthly}\")\n",
    "print(f\"Annual Mean Return: {mu_constrained3_annual}\")\n",
    "print(f\"Monthly Volatility: {sigma_constrained3_monthly}\")\n",
    "print(f\"Annual Volatility: {sigma_constrained3_annual}\")\n",
    "print(f\"Sharpe Ratio: {sr_constrained3}\")\n",
    "print(f\"Tracking Error: {constrained3_te}\")\n",
    "print(f\"Number of Investments: {num_inv_constrained3}\")\n",
    "print(f\"Number of Sectors: {num_sectors_constrained3}\")\n",
    "print(f\"Total Emissions: {constrained3_emissions}\")\n",
    "print(\"Sector Weights:\\n\", c3_sector_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e99174",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad6a997",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Contrained Portfolio - Tangency Portfolio with 20% less Carbon Intensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "1c2b333c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "3dddfcc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 15 Weights:\n",
      "        Weight\n",
      "NEE  0.032275\n",
      "BJ   0.032101\n",
      "UE   0.031460\n",
      "DOC  0.031173\n",
      "OXY  0.030709\n",
      "GE   0.030330\n",
      "HRB  0.030302\n",
      "WOR  0.029825\n",
      "IQV  0.029790\n",
      "NFG  0.027333\n",
      "NOW  0.026942\n",
      "APO  0.026909\n",
      "FDX  0.026564\n",
      "AEO  0.026408\n",
      "RYI  0.025764\n",
      "mu_constrained4_annual: 0.2169453569007307\n",
      "sigma_constrained4_annual: 0.23209487057527817\n",
      "sr_constrained4: 0.852922764572389\n",
      "constrained4_te: 0.006770537758857201\n",
      "num_inv_constrained4: 65\n",
      "num_sectors_constrained4: 10\n",
      "constrained4_emissions: 3763342.7704585786\n",
      "Sector Weights:\n",
      " TRBC Economic Sector Name\n",
      "Basic Materials           0.058141\n",
      "Consumer Cyclicals        0.172219\n",
      "Consumer Non-Cyclicals    0.128328\n",
      "Energy                    0.069057\n",
      "Financials                0.151510\n",
      "Healthcare                0.034553\n",
      "Industrials               0.058908\n",
      "Real Estate               0.120326\n",
      "Technology                0.097508\n",
      "Utilities                 0.109449\n",
      "Name: Weight, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pypfopt import expected_returns, risk_models\n",
    "\n",
    "# Load data\n",
    "emissions_data = pd.read_csv(r\"C:\\Users\\adhit\\OneDrive\\desktop\\GDS\\Green Data Science project\\DATA\\Emissions Data_66 stocks.csv\")\n",
    "returns_data = pd.read_csv(r\"C:\\Users\\adhit\\OneDrive\\desktop\\GDS\\Green Data Science project\\DATA\\Market Price_66 stocks.csv\", index_col='Date', parse_dates=True, usecols=range(67))\n",
    "sector_data = pd.read_csv(r\"C:\\Users\\adhit\\OneDrive\\desktop\\GDS\\Green Data Science project\\DATA\\sector.csv\")\n",
    "\n",
    "# Data Cleansing\n",
    "emissions_data.columns = emissions_data.columns.str.strip()\n",
    "emissions_data = emissions_data.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n",
    "emissions_data['CO2 Equivalent Emissions Direct, Scope 1'] = emissions_data['CO2 Equivalent Emissions Direct, Scope 1'].str.replace(',', '').astype(float)\n",
    "emissions_data['CO2 Equivalent Emissions Indirect, Scope 2'] = emissions_data['CO2 Equivalent Emissions Indirect, Scope 2'].str.replace(',', '').astype(float)\n",
    "\n",
    "# Calculate total emissions for each instrument\n",
    "emissions_data['Total Emissions'] = emissions_data['CO2 Equivalent Emissions Direct, Scope 1'] + emissions_data['CO2 Equivalent Emissions Indirect, Scope 2']\n",
    "\n",
    "# Convert Carbon Intensity to numeric\n",
    "emissions_data['Carbon Intensity'] = emissions_data['Carbon Intensity'].str.replace(',', '').astype(float)\n",
    "\n",
    "# Ensure the tickers in returns_data match those in emissions_data\n",
    "tickers = returns_data.columns.intersection(emissions_data['Instrument'])\n",
    "\n",
    "# Filter returns_data and emissions_data to include only matching tickers\n",
    "returns_data_filtered = returns_data[tickers]\n",
    "emissions_data_filtered = emissions_data.set_index('Instrument').loc[tickers]\n",
    "\n",
    "# Calculate mean historical returns and sample covariance matrix\n",
    "mu = expected_returns.mean_historical_return(returns_data_filtered, frequency=12, returns_data=True)\n",
    "S = risk_models.risk_matrix(returns_data_filtered, method='ledoit_wolf', returns_data=True)\n",
    "\n",
    "# Define constraints\n",
    "def calculate_portfolio_return(weights, mu):\n",
    "    return np.dot(weights, mu)\n",
    "\n",
    "def calculate_portfolio_volatility(weights, S):\n",
    "    return np.sqrt(np.dot(weights.T, np.dot(S, weights)))\n",
    "\n",
    "def calculate_sharpe_ratio(weights, mu, S, risk_free_rate=0.02):\n",
    "    portfolio_return = calculate_portfolio_return(weights, mu)\n",
    "    portfolio_volatility = calculate_portfolio_volatility(weights, S)\n",
    "    return (portfolio_return - risk_free_rate) / portfolio_volatility\n",
    "\n",
    "def calculate_carbon_intensity(weights, carbon_intensity):\n",
    "    return np.dot(weights, carbon_intensity)\n",
    "\n",
    "# Heuristic optimization\n",
    "n_assets = len(mu)\n",
    "best_sharpe_ratio = -np.inf\n",
    "best_weights = np.zeros(n_assets)\n",
    "carbon_intensity_threshold = 0.8 * emissions_data_filtered['Carbon Intensity'].mean()\n",
    "\n",
    "for _ in range(10000):  # Number of iterations\n",
    "    weights = np.random.random(n_assets)\n",
    "    weights /= np.sum(weights)  # Normalize weights to sum to 1\n",
    "    \n",
    "    portfolio_sharpe_ratio = calculate_sharpe_ratio(weights, mu, S)\n",
    "    portfolio_carbon_intensity = calculate_carbon_intensity(weights, emissions_data_filtered['Carbon Intensity'].values)\n",
    "    \n",
    "    if portfolio_carbon_intensity <= carbon_intensity_threshold and portfolio_sharpe_ratio > best_sharpe_ratio:\n",
    "        best_sharpe_ratio = portfolio_sharpe_ratio\n",
    "        best_weights = weights\n",
    "\n",
    "# Convert weights to a DataFrame\n",
    "constrained4_weights = pd.DataFrame(best_weights, index=returns_data_filtered.columns, columns=['Weight'])\n",
    "top15_constrained4_weights = constrained4_weights[constrained4_weights['Weight'] > 10**-4].sort_values(by='Weight', ascending=False).head(15)\n",
    "print(\"Top 15 Weights:\\n\", top15_constrained4_weights)\n",
    "\n",
    "# Calculate returns for the constrained portfolio\n",
    "constrained4_returns = (constrained4_weights.T.values * returns_data_filtered).sum(axis=1)\n",
    "\n",
    "# Calculate monthly and annual mean returns\n",
    "mu_constrained4_monthly = constrained4_returns.mean()\n",
    "mu_constrained4_annual = (1 + mu_constrained4_monthly) ** 12 - 1\n",
    "\n",
    "# Calculate monthly and annual standard deviation (volatility)\n",
    "sigma_sq_constrained4 = constrained4_returns.var(ddof=1)\n",
    "sigma_constrained4_monthly = constrained4_returns.std(ddof=1)\n",
    "sigma_constrained4_annual = sigma_constrained4_monthly * np.sqrt(12)\n",
    "\n",
    "# Calculate Sharpe Ratio\n",
    "sr_constrained4 = mu_constrained4_monthly / sigma_constrained4_monthly * np.sqrt(12)\n",
    "\n",
    "# Calculate tracking error\n",
    "benchmark_returns = returns_data_filtered.mean(axis=1)  # Assuming benchmark returns are the average returns\n",
    "constrained4_te = (constrained4_returns - benchmark_returns.values).std(ddof=1)\n",
    "\n",
    "# Count the number of investments and sectors in the constrained portfolio\n",
    "num_inv_constrained4 = np.sum(constrained4_weights['Weight'].values > 10**-4)\n",
    "num_sectors_constrained4 = sector_data.merge(constrained4_weights[constrained4_weights['Weight'] > 10**-4], \n",
    "                                             left_on='Instrument', right_index=True)['TRBC Economic Sector Name'].nunique()\n",
    "\n",
    "# Calculate the total emissions for the constrained portfolio\n",
    "constrained4_emissions = (constrained4_weights['Weight'].values * emissions_data_filtered['Total Emissions'].values).sum()\n",
    "\n",
    "# Calculate sector weights\n",
    "c4_sector_weights = constrained4_weights.merge(sector_data, left_index=True, right_on='Instrument').groupby('TRBC Economic Sector Name')['Weight'].sum()\n",
    "\n",
    "# Print the results\n",
    "print(f\"mu_constrained4_annual: {mu_constrained4_annual}\")\n",
    "print(f\"sigma_constrained4_annual: {sigma_constrained4_annual}\")\n",
    "print(f\"sr_constrained4: {sr_constrained4}\")\n",
    "print(f\"constrained4_te: {constrained4_te}\")\n",
    "print(f\"num_inv_constrained4: {num_inv_constrained4}\")\n",
    "print(f\"num_sectors_constrained4: {num_sectors_constrained4}\")\n",
    "print(f\"constrained4_emissions: {constrained4_emissions}\")\n",
    "print(\"Sector Weights:\\n\", c4_sector_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da90608",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "d928229f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Constrained Portfolio - Tangency w/ 20% CI reduction & Sector Balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2800ba35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "3d636fdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constrained Portfolio Weights:\n",
      "       Weight\n",
      "AA   0.000000\n",
      "AEO  0.000000\n",
      "AIZ  0.056533\n",
      "AKR  0.000000\n",
      "AMP  0.000000\n",
      "..        ...\n",
      "WHR  0.000000\n",
      "WOR  0.042424\n",
      "WSR  0.004429\n",
      "XHR  0.000000\n",
      "XOM  0.000000\n",
      "\n",
      "[66 rows x 1 columns]\n",
      "Monthly Mean Return: 0.021762686160174738\n",
      "Annual Mean Return: 0.29479335881890556\n",
      "Monthly Volatility: 0.05108626601909898\n",
      "Annual Volatility: 0.17696801662811776\n",
      "Sharpe Ratio: 1.4757030049722746\n",
      "Tracking Error: 0.011280802996756295\n",
      "Number of Investments: 14\n",
      "Number of Sectors: 10\n",
      "Total Emissions: 7959434.731711317\n",
      "Sector Weights:\n",
      "TRBC Economic Sector Name\n",
      "Basic Materials           0.042424\n",
      "Consumer Cyclicals        0.216667\n",
      "Consumer Non-Cyclicals    0.092424\n",
      "Energy                    0.042424\n",
      "Financials                0.157576\n",
      "Healthcare                0.021212\n",
      "Industrials               0.098485\n",
      "Real Estate               0.106061\n",
      "Technology                0.137879\n",
      "Utilities                 0.084848\n",
      "Name: Weight, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pypfopt import EfficientFrontier, expected_returns, risk_models\n",
    "\n",
    "# Ensure 'emissions_data' and 'sector_data' have numeric columns where expected\n",
    "emissions_data = emissions_data.apply(pd.to_numeric, errors='coerce')\n",
    "sector_data['Instrument'] = sector_data['Instrument'].astype(str)\n",
    "returns_data.columns = returns_data.columns.astype(str)\n",
    "\n",
    "# Assuming benchmark_weights is a numpy array\n",
    "benchmark_weights_df = pd.DataFrame(benchmark_weights, index=returns_data.columns, columns=['Weight'])\n",
    "\n",
    "# Merge with sector data\n",
    "sector_weights = benchmark_weights_df.merge(sector_data, left_index=True, right_on='Instrument').groupby('TRBC Economic Sector Name')['Weight'].sum()\n",
    "\n",
    "lower_bound = (sector_weights * 0.7).to_dict()\n",
    "upper_bound = (sector_weights * 1.3).to_dict()\n",
    "\n",
    "ef_constrained5 = EfficientFrontier(mu, S, weight_bounds=(0, 1))\n",
    "\n",
    "ef_constrained5.add_constraint(lambda w: CI(w, emissions_data['Carbon Intensity']) <= 0.8 * benchmark_emissions)\n",
    "ef_constrained5.add_sector_constraints(sector_mapper, lower_bound, upper_bound)\n",
    "weights = ef_constrained5.max_sharpe()\n",
    "\n",
    "constrained5_weights = pd.DataFrame.from_dict(weights, orient='index', columns=['Weight'])\n",
    "constrained5_returns = (constrained5_weights.T.values * returns_data.values).sum(axis=1)\n",
    "\n",
    "mu_constrained5_monthly = constrained5_returns.mean()\n",
    "mu_constrained5_annual = (1 + mu_constrained5_monthly) ** 12 - 1\n",
    "\n",
    "sigma_sq_constrained5 = constrained5_returns.var(ddof=1)\n",
    "sigma_constrained5_monthly = constrained5_returns.std(ddof=1)\n",
    "sigma_constrained5_annual = sigma_constrained5_monthly * np.sqrt(12)\n",
    "\n",
    "sr_constrained5 = mu_constrained5_monthly / sigma_constrained5_monthly * np.sqrt(12)\n",
    "\n",
    "constrained5_te = (constrained5_returns - tangency_returns).std(ddof=1)\n",
    "\n",
    "num_inv_constrained5 = np.sum(constrained5_weights.values > 0)\n",
    "num_sectors_constrained5 = sector_data.merge(constrained5_weights[constrained5_weights['Weight'] > 0], \n",
    "                                             left_on='Instrument', right_index=True)['TRBC Economic Sector Name'].nunique()\n",
    "\n",
    "constrained5_emissions = (constrained5_weights['Weight'].values * emissions_data.sum(axis=1).values).sum()\n",
    "c5_sector_weights = constrained5_weights.merge(sector_data, left_index=True, right_on='Instrument').groupby('TRBC Economic Sector Name')['Weight'].sum()\n",
    "\n",
    "print(f\"Constrained Portfolio Weights:\\n{constrained5_weights}\")\n",
    "print(f\"Monthly Mean Return: {mu_constrained5_monthly}\")\n",
    "print(f\"Annual Mean Return: {mu_constrained5_annual}\")\n",
    "print(f\"Monthly Volatility: {sigma_constrained5_monthly}\")\n",
    "print(f\"Annual Volatility: {sigma_constrained5_annual}\")\n",
    "print(f\"Sharpe Ratio: {sr_constrained5}\")\n",
    "print(f\"Tracking Error: {constrained5_te}\")\n",
    "print(f\"Number of Investments: {num_inv_constrained5}\")\n",
    "print(f\"Number of Sectors: {num_sectors_constrained5}\")\n",
    "print(f\"Total Emissions: {constrained5_emissions}\")\n",
    "print(f\"Sector Weights:\\n{c5_sector_weights}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "0830b41b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "4d3d12d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Summary Dataframe Composition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a261bd2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "bfb10c96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_c641a\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_c641a_level0_col0\" class=\"col_heading level0 col0\" >Monthly Return</th>\n",
       "      <th id=\"T_c641a_level0_col1\" class=\"col_heading level0 col1\" >Annual Return</th>\n",
       "      <th id=\"T_c641a_level0_col2\" class=\"col_heading level0 col2\" >Monthly Volatility</th>\n",
       "      <th id=\"T_c641a_level0_col3\" class=\"col_heading level0 col3\" >Annual Volatility</th>\n",
       "      <th id=\"T_c641a_level0_col4\" class=\"col_heading level0 col4\" >Sharpe Ratio</th>\n",
       "      <th id=\"T_c641a_level0_col5\" class=\"col_heading level0 col5\" >Number of Investments</th>\n",
       "      <th id=\"T_c641a_level0_col6\" class=\"col_heading level0 col6\" >Number of Sectors</th>\n",
       "      <th id=\"T_c641a_level0_col7\" class=\"col_heading level0 col7\" >Benchmark</th>\n",
       "      <th id=\"T_c641a_level0_col8\" class=\"col_heading level0 col8\" >Tracking Error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_c641a_level0_row0\" class=\"row_heading level0 row0\" >Market Cap-Weighted</th>\n",
       "      <td id=\"T_c641a_row0_col0\" class=\"data row0 col0\" >0.0143</td>\n",
       "      <td id=\"T_c641a_row0_col1\" class=\"data row0 col1\" >0.1854</td>\n",
       "      <td id=\"T_c641a_row0_col2\" class=\"data row0 col2\" >0.0691</td>\n",
       "      <td id=\"T_c641a_row0_col3\" class=\"data row0 col3\" >0.2393</td>\n",
       "      <td id=\"T_c641a_row0_col4\" class=\"data row0 col4\" >0.7159</td>\n",
       "      <td id=\"T_c641a_row0_col5\" class=\"data row0 col5\" >66</td>\n",
       "      <td id=\"T_c641a_row0_col6\" class=\"data row0 col6\" >66</td>\n",
       "      <td id=\"T_c641a_row0_col7\" class=\"data row0 col7\" ></td>\n",
       "      <td id=\"T_c641a_row0_col8\" class=\"data row0 col8\" >0.0000%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c641a_level0_row1\" class=\"row_heading level0 row1\" >Tangency</th>\n",
       "      <td id=\"T_c641a_row1_col0\" class=\"data row1 col0\" >0.0241</td>\n",
       "      <td id=\"T_c641a_row1_col1\" class=\"data row1 col1\" >0.3307</td>\n",
       "      <td id=\"T_c641a_row1_col2\" class=\"data row1 col2\" >0.0502</td>\n",
       "      <td id=\"T_c641a_row1_col3\" class=\"data row1 col3\" >0.1737</td>\n",
       "      <td id=\"T_c641a_row1_col4\" class=\"data row1 col4\" >1.6641</td>\n",
       "      <td id=\"T_c641a_row1_col5\" class=\"data row1 col5\" >11</td>\n",
       "      <td id=\"T_c641a_row1_col6\" class=\"data row1 col6\" >6</td>\n",
       "      <td id=\"T_c641a_row1_col7\" class=\"data row1 col7\" ></td>\n",
       "      <td id=\"T_c641a_row1_col8\" class=\"data row1 col8\" >0.0000%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c641a_level0_row2\" class=\"row_heading level0 row2\" >Market Cap-Weighted w/ 10% CI Reduction</th>\n",
       "      <td id=\"T_c641a_row2_col0\" class=\"data row2 col0\" >0.0139</td>\n",
       "      <td id=\"T_c641a_row2_col1\" class=\"data row2 col1\" >0.1797</td>\n",
       "      <td id=\"T_c641a_row2_col2\" class=\"data row2 col2\" >0.0691</td>\n",
       "      <td id=\"T_c641a_row2_col3\" class=\"data row2 col3\" >0.2393</td>\n",
       "      <td id=\"T_c641a_row2_col4\" class=\"data row2 col4\" >0.6954</td>\n",
       "      <td id=\"T_c641a_row2_col5\" class=\"data row2 col5\" >66</td>\n",
       "      <td id=\"T_c641a_row2_col6\" class=\"data row2 col6\" >3</td>\n",
       "      <td id=\"T_c641a_row2_col7\" class=\"data row2 col7\" >Market-Cap</td>\n",
       "      <td id=\"T_c641a_row2_col8\" class=\"data row2 col8\" >0.0000%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c641a_level0_row3\" class=\"row_heading level0 row3\" >Market Cap-Weighted w/ 20% CI Reduction</th>\n",
       "      <td id=\"T_c641a_row3_col0\" class=\"data row3 col0\" >0.0137</td>\n",
       "      <td id=\"T_c641a_row3_col1\" class=\"data row3 col1\" >0.1773</td>\n",
       "      <td id=\"T_c641a_row3_col2\" class=\"data row3 col2\" >0.0691</td>\n",
       "      <td id=\"T_c641a_row3_col3\" class=\"data row3 col3\" >0.2393</td>\n",
       "      <td id=\"T_c641a_row3_col4\" class=\"data row3 col4\" >0.6866</td>\n",
       "      <td id=\"T_c641a_row3_col5\" class=\"data row3 col5\" >66</td>\n",
       "      <td id=\"T_c641a_row3_col6\" class=\"data row3 col6\" >3</td>\n",
       "      <td id=\"T_c641a_row3_col7\" class=\"data row3 col7\" >Market-Cap</td>\n",
       "      <td id=\"T_c641a_row3_col8\" class=\"data row3 col8\" >0.0000%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c641a_level0_row4\" class=\"row_heading level0 row4\" >Market Cap-Weighted w/ 50% CI Reduction</th>\n",
       "      <td id=\"T_c641a_row4_col0\" class=\"data row4 col0\" >0.0137</td>\n",
       "      <td id=\"T_c641a_row4_col1\" class=\"data row4 col1\" >0.1770</td>\n",
       "      <td id=\"T_c641a_row4_col2\" class=\"data row4 col2\" >0.0691</td>\n",
       "      <td id=\"T_c641a_row4_col3\" class=\"data row4 col3\" >0.2393</td>\n",
       "      <td id=\"T_c641a_row4_col4\" class=\"data row4 col4\" >0.6856</td>\n",
       "      <td id=\"T_c641a_row4_col5\" class=\"data row4 col5\" >58</td>\n",
       "      <td id=\"T_c641a_row4_col6\" class=\"data row4 col6\" >10</td>\n",
       "      <td id=\"T_c641a_row4_col7\" class=\"data row4 col7\" >Market-Cap</td>\n",
       "      <td id=\"T_c641a_row4_col8\" class=\"data row4 col8\" >0.0186%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c641a_level0_row5\" class=\"row_heading level0 row5\" >Tangency w/ 20% CI Reduction</th>\n",
       "      <td id=\"T_c641a_row5_col0\" class=\"data row5 col0\" >0.0165</td>\n",
       "      <td id=\"T_c641a_row5_col1\" class=\"data row5 col1\" >0.2169</td>\n",
       "      <td id=\"T_c641a_row5_col2\" class=\"data row5 col2\" >0.0670</td>\n",
       "      <td id=\"T_c641a_row5_col3\" class=\"data row5 col3\" >0.2321</td>\n",
       "      <td id=\"T_c641a_row5_col4\" class=\"data row5 col4\" >0.8529</td>\n",
       "      <td id=\"T_c641a_row5_col5\" class=\"data row5 col5\" >65</td>\n",
       "      <td id=\"T_c641a_row5_col6\" class=\"data row5 col6\" >10</td>\n",
       "      <td id=\"T_c641a_row5_col7\" class=\"data row5 col7\" >Tangency</td>\n",
       "      <td id=\"T_c641a_row5_col8\" class=\"data row5 col8\" >0.6771%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c641a_level0_row6\" class=\"row_heading level0 row6\" >Tangency w/ 20% CI Reduction & Sector Balance</th>\n",
       "      <td id=\"T_c641a_row6_col0\" class=\"data row6 col0\" >0.0218</td>\n",
       "      <td id=\"T_c641a_row6_col1\" class=\"data row6 col1\" >0.2948</td>\n",
       "      <td id=\"T_c641a_row6_col2\" class=\"data row6 col2\" >0.0511</td>\n",
       "      <td id=\"T_c641a_row6_col3\" class=\"data row6 col3\" >0.1770</td>\n",
       "      <td id=\"T_c641a_row6_col4\" class=\"data row6 col4\" >1.4757</td>\n",
       "      <td id=\"T_c641a_row6_col5\" class=\"data row6 col5\" >14</td>\n",
       "      <td id=\"T_c641a_row6_col6\" class=\"data row6 col6\" >10</td>\n",
       "      <td id=\"T_c641a_row6_col7\" class=\"data row6 col7\" >Tangency</td>\n",
       "      <td id=\"T_c641a_row6_col8\" class=\"data row6 col8\" >1.1281%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x2d287027d90>"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create individual DataFrames for each portfolio with the provided data\n",
    "bp = pd.DataFrame({\n",
    "    'Market Cap-Weighted': [mu_benchmark_monthly, mu_benchmark_annual, sigma_benchmark_monthly,\n",
    "                            sigma_benchmark_annual, sr_benchmark, num_inv_benchmark, num_sectors_benchmark, '', 0]\n",
    "}, index=['Monthly Return', 'Annual Return', 'Monthly Volatility', 'Annual Volatility',\n",
    "          'Sharpe Ratio', 'Number of Investments', 'Number of Sectors', 'Benchmark', 'Tracking Error']).T\n",
    "\n",
    "tp = pd.DataFrame({\n",
    "    'Tangency': [mu_tangency_monthly, mu_tangency_annual, sigma_tangency_monthly,\n",
    "                 sigma_tangency_annual, sr_tangency, num_inv_tangency, num_sectors_tangency, '', 0]\n",
    "}, index=['Monthly Return', 'Annual Return', 'Monthly Volatility', 'Annual Volatility',\n",
    "          'Sharpe Ratio', 'Number of Investments', 'Number of Sectors', 'Benchmark', 'Tracking Error']).T\n",
    "\n",
    "p1 = pd.DataFrame({\n",
    "    'Market Cap-Weighted w/ 10% CI Reduction': [mu_constrained1_monthly, mu_constrained1_annual, sigma_constrained1_monthly,\n",
    "                                                sigma_constrained1_annual, sr_constrained1, num_inv_constrained1, num_sectors_constrained1, 'Market-Cap', 100*constrained1_te]\n",
    "}, index=['Monthly Return', 'Annual Return', 'Monthly Volatility', 'Annual Volatility',\n",
    "          'Sharpe Ratio', 'Number of Investments', 'Number of Sectors', 'Benchmark', 'Tracking Error']).T\n",
    "\n",
    "p2 = pd.DataFrame({\n",
    "    'Market Cap-Weighted w/ 20% CI Reduction': [mu_constrained2_monthly, mu_constrained2_annual, sigma_constrained2_monthly,\n",
    "                                                sigma_constrained2_annual, sr_constrained2, num_inv_constrained2, num_sectors_constrained2, 'Market-Cap', 100*constrained2_te]\n",
    "}, index=['Monthly Return', 'Annual Return', 'Monthly Volatility', 'Annual Volatility',\n",
    "          'Sharpe Ratio', 'Number of Investments', 'Number of Sectors', 'Benchmark', 'Tracking Error']).T\n",
    "\n",
    "p3 = pd.DataFrame({\n",
    "    'Market Cap-Weighted w/ 50% CI Reduction': [mu_constrained3_monthly, mu_constrained3_annual, sigma_constrained3_monthly,\n",
    "                                                sigma_constrained3_annual, sr_constrained3, num_inv_constrained3, num_sectors_constrained3, 'Market-Cap', 100*constrained3_te]\n",
    "}, index=['Monthly Return', 'Annual Return', 'Monthly Volatility', 'Annual Volatility',\n",
    "          'Sharpe Ratio', 'Number of Investments', 'Number of Sectors', 'Benchmark', 'Tracking Error']).T\n",
    "\n",
    "p4 = pd.DataFrame({\n",
    "    'Tangency w/ 20% CI Reduction': [mu_constrained4_monthly, mu_constrained4_annual, sigma_constrained4_monthly,\n",
    "                                     sigma_constrained4_annual, sr_constrained4, num_inv_constrained4, num_sectors_constrained4, 'Tangency', 100*constrained4_te]\n",
    "}, index=['Monthly Return', 'Annual Return', 'Monthly Volatility', 'Annual Volatility',\n",
    "          'Sharpe Ratio', 'Number of Investments', 'Number of Sectors', 'Benchmark', 'Tracking Error']).T\n",
    "\n",
    "p5 = pd.DataFrame({\n",
    "    'Tangency w/ 20% CI Reduction & Sector Balance': [mu_constrained5_monthly, mu_constrained5_annual, sigma_constrained5_monthly,\n",
    "                                                      sigma_constrained5_annual, sr_constrained5, num_inv_constrained5, num_sectors_constrained5, 'Tangency', 100*constrained5_te]\n",
    "}, index=['Monthly Return', 'Annual Return', 'Monthly Volatility', 'Annual Volatility',\n",
    "          'Sharpe Ratio', 'Number of Investments', 'Number of Sectors', 'Benchmark', 'Tracking Error']).T\n",
    "\n",
    "# Concatenate all DataFrames\n",
    "df_summary = pd.concat([bp, tp, p1, p2, p3, p4, p5])\n",
    "\n",
    "# Format the DataFrame\n",
    "df_summary = df_summary.style.format({\n",
    "    'Monthly Return': '{:,.4f}',\n",
    "    'Annual Return': '{:,.4f}',\n",
    "    'Monthly Volatility': '{:,.4f}',\n",
    "    'Annual Volatility': '{:,.4f}',\n",
    "    'Sharpe Ratio': '{:,.4f}',\n",
    "    'Number of Investments': '{:,.0f}',\n",
    "    'Number of Sectors': '{:,.0f}',\n",
    "    'Tracking Error': '{:,.4f}%'\n",
    "})\n",
    "\n",
    "# Convert styled DataFrame back to regular DataFrame\n",
    "df_summary_regular = df_summary.data\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df_summary_regular.to_csv('df_summary.csv', index=True)\n",
    "\n",
    "# Display the styled DataFrame\n",
    "df_summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8092e472",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
